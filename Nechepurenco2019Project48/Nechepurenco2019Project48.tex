\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
%\NOREVIEWERNOTES
\title
    [Образец оформления статьи для публикации] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Мультимоделирование, привилегированное обучение}
\author
    [Нечепуренко~И.\,О.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Нечепуренко~И.\,О., Нейчев~Р.\,Г., Стрижов~В.\,В.} % основной список авторов, выводимый в оглавление
    [Нечепуренко~И.\,О.$^1$, Нейчев~Р.\,Г.$^2$, Стрижов~В.\,В.$^2$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
    {Работа выполнена при финансовой поддержке РФФИ, проект \No\,00-00-00000.
   Научный руководитель:  Стрижов~В.\,В.
   Задачу поставил:  Эксперт~И.\,О.
    Консультант:  Консультант~И.\,О.}
\email
    {author@site.ru}
\organization
    {$^1$Организация; $^2$Организация}
\abstract
    {  Цель данной работы -  опробовать различные методы построения моделей оптимальной вычислительной сложности.  Затраты по времени и памяти для работы модели играют очень важную роль в большинстве сфер человеческой жизнедеятельности.  Носимая электроника и защищенные устройства для решения задач биометрии, устройства автоматической обработки телеметрических данных, системы потоковой аналитики результатов коллизий Большого Адронного Колайдера — это лишь малая доля случаев, когда  требуются достаточно быстрые алгоритмы машинного обучения. Существует широкиий спектр способов уменьшения сложности модели.  Один них - это разбиение объектов на подобласти,  и описание данных в каждой своей собственной моделью. Этот способ называется мультимоделированием (в иноязычной литературе Mixture experts).  Другой способ - мета-обучение (Metalearning),  метод, основанный на парадгме учителя-ученика, но при этом в качестве учителя могут выступать не только ответы на экспериментальных данных, но и результаты работы другой модели учителя. В случае добавления дополнительной, априорной информации, можно значительно улучшить результаты сходимость происходящего во время обучения оптимизационного процесса,  снизить сложность модели, а также повысить итоговое качество модели. Эти свойства были проверены на реальных данных.

\bigskip
\textbf{Ключевые слова}: \emph {машинное обучение, мета-обучение, мультимоделирование }.}
\titleEng
    {JMLDA paper example: file jmlda-example.tex}
\authorEng
    {Author~F.\,S.$^1$, CoAuthor~F.\,S.$^2$, Name~F.\,S.$^2$}
\organizationEng
    {$^1$Organization; $^2$Organization}
\abstractEng
    {This document is an example of paper prepared with \LaTeXe\
    typesetting system and style file \texttt{jmlda.sty}.

    \bigskip
    \textbf{Keywords}: \emph{keyword, keyword, more keywords}.}
\begin{document}
\maketitle
%\linenumbers
\section{Введение}

Основное сообщение — чему посвящена работа (одна-две фразы)
Рассматривается задача построения алгоритмов анализа данных максимальной точности с ограниченными затратами ресурсов. Конкретно работа посвящена самому распространенному типу машинного обучения - обучению с учителем. Обычно в промышлен ности и науке машинное обучение связанно с обработкой больших массивов данных и итерационными процессами оптимизации, а это влечет за собой сильные затраты по ресурсам, которые не могт себе позволить даже крупные компании. Рассматриваемая нами задача применима практически во всех сферах науки и бизнеса.

Существуют различные подходы к решению задачи. Один из них - мультимоделирование. Нам интересен один конкретный [1] алгоритм: смесь экспертов. В реализации этого алгоритма специальная функция, именуемая шлюзовой, опрееляет ценность предсказаний конкретного эксперта. Одной из полезных особенностей способа можно назвать возможность отфильтровывать "слабые" модели. 

Другой подход - модификация алгоритма обучения с учителем, в котором в роли учителя могут выступить не только экспериментальные данные, но и ответы машины, обученной на более полных данных либо более сложным алгоритмом.
Два метода, основанных на парадигме "машина учит машину":  дистилляция[2] и контроль сходства[3], были обобщены[4].


Современное состояние области (два-четыре абзаца)

Рассматривваемые нами алгоритмы достаточно молодые: например,контроль сходства был представлен Вапником в 2009 г., а метод дистилляции - в 2015 -м году Д. Хинтоном.  Тем не менее, эти алгоритмы уже используются на практике: например, не так давно они использовались для использования энергии датацентрами Яндекса. 


Что предлагается (два абзаца)

Предлагается на реальных данных: данных о ценах энергопотребления в Польше в зависимости от времени протестировать известные алгоритмы, сравнить сложности вычисления и достигаемые качества при различных  реализациях.


После аннотации, но перед первым разделом,
располагается введение, включающее в себя
описание предметной области,
обоснование актуальности задачи,
краткий обзор известных результатов,
и~т.\,п~\cite{author09anyscience,myHandbook,author09first-word-of-the-title,voron06latex,author-and-co2007,Lvovsky03}.

\section{Название раздела}
Данный документ демонстрирует оформление статьи,
подаваемой в электронную систему подачи статей \url{http://jmlda.org/papers} для публикации в журнале <<Машинной обучение и анализ данных>>.
Более подробные инструкции по~стилевому файлу \texttt{jmlda.sty}
и~использованию издательской системы \LaTeXe\
находятся в~документе \texttt{authors-guide.pdf}.
Работу над статьёй удобно начинать с~правки \TeX-файла данного документа.

\paragraph{Название параграфа.}
%Первый раздел может содержать формальную постановку задачи,
%основные определения и~обозначения,
%известные факты, необходимые для понимания основных результатов работы,
%и~т.\,п.
Нет ограничений на~количество разделов и~параграфов в~статье.
Разделы и~параграфы не~нумеруются.

\paragraph{Теоретическую часть работы} желательно структурировать
с~помощью окружений
Def, Axiom, Hypothesis, Problem, Lemma, Theorem, Corollary, State, Example, Remark.

\begin{Def}
    Математический текст \emph{хорошо структурирован},
    если в~нём выделены определения, теоремы, утверждения, примеры, и~т.\,д.,
    а~неформальные рассуждения (мотивации, интерпретации)
    вынесены в~отдельные параграфы.
\end{Def}

\begin{State}
    Мотивации и~интерпретации наиболее важны для понимания сути работы.
\end{State}

\begin{Theorem}
    Не~менее $90\%$ коллег, заинтересовавшихся Вашей статьёй,
    прочитают в~ней не~более~$10\%$ текста.
\end{Theorem}

\begin{Proof}
    Причём это будут именно те~разделы, которые не содержат формул.
\end{Proof}

\begin{Remark}
    Выше показано применение окружений
    Def, Theorem, State, Remark, Proof.
\end{Remark}

\section{Некоторые формулы}

Образец формулы: $f(x_i,\alpha^\gamma)$.

Образец выключной формулы без номера:
\[
    y(x,\alpha) =
    \begin{cases}
        -1, & \text{если } f(x,\alpha)<0;  \\
        +1, & \text{если } f(x,\alpha)\geq 0.
    \end{cases}
\]

Образец выключной формулы с номером:
\begin{equation}
\label{eq:cases}
    y(x,\alpha) =
    \begin{cases}
        -1, & \text{если } f(x,\alpha)<0;  \\
        +1, & \text{если } f(x,\alpha)\geq 0.
    \end{cases}
\end{equation}

Образец выключной формулы, разбитой на две строки с~помощью окружения align:
\begin{align}
    R'_N(F)
        = \frac1N \sum_{i=1}^N
        \Bigl(
            & P(+1\cond x_i) C\bigl(+1,F(x_i)\bigr)+{}
        \notag % подавили номер у первой строки
    \\ {}+{}
            & P(-1\cond x_i) C\bigl(-1,F(x_i)\bigr)
        \Bigr).
        \label{eq:R(F)}
\end{align}

Образцы ссылок: формулы~\eqref{eq:cases} и~\eqref{eq:R(F)}.

\section{Пример илюстрации}

Рисунки вставляются командой \verb|\includegraphics|,
желательно с~выравниванием по~ширине колонки: \verb|[width=\linewidth]|.

Практически все популярные пакеты рисуют графики с подписями, которые трудно читать на бумаге и на слайдах из-за малого размера шрифта. Шрифт на графиках (подписи осей и цифры на осях) должны быть такого же размера, что и основной текст.

\begin{figure}[h]
  \subfloat[Первый рисунок]{\includegraphics[width=0.5\textwidth]{figExample1}}
  \subfloat[Второй рисунок]{\includegraphics[width=0.5\textwidth]{figExample2}}\\
\caption{Подпись должна размещаться под рисунком. }
\label{fg:Example}
\end{figure}

При значительном количестве рисунков рекомендуется группировать иx в одном окружении \verb|{figure}|, как это сделано на рис.~\ref{fg:Example}.

\section{Пример таблицы}
Подпись делается \emph{над таблицей}, см.~таблицу~\ref{TabExample}.


\begin{table}[t]%\small
    \caption{Подпись размещается над таблицей.}
    \label{TabExample}
    \centering\medskip%\tabcolsep=2pt%\small
    \begin{tabular}{lrrr}
    \headline
        Задача
            & \multicolumn{1}{c}{CCEL}
            & \multicolumn{1}{c}{boosting} \\
    \headline
        {\tt Cancer}
            & $\mathbf{3.46}  \pm 0.37$ (3.16)
            & $4.14 \pm 1.48$ \\
        {\tt German}
            & $\mathbf{25.78} \pm 0.65$ (1.74)
            & $29.48 \pm 0.93$ \\
        {\tt Hepatitis}
            & $18.38 \pm 1.43$ (2.87)
            & $19.90 \pm 1.80$ \\
    \hline
    \end{tabular}
\end{table}

\section{Заключение}
Желательно, чтобы этот раздел был, причём он не~должен дословно повторять аннотацию.
Обычно здесь отмечают,
каких результатов удалось добиться,
какие проблемы остались открытыми.

[1] Yuksel Seniha Esen, Wilson Joseph N., Gader Paul D. Twenty Years of Mixture
of Experts // IEEE Transactions on Neural Networks and Learning Systems. 2012.
Т. 23, № 8. С. 1177–1193.

[2] Hinton Geoffrey E., Vinyals Oriol, Dean Jeffrey. Distilling the Knowledge
in a Neural Network // CoRR. 2015. Т. abs/1503.02531. URL:
http://arxiv.org/abs/1503.02531.


[3]  Vapnik V., Vashist A. A new learning paradigm: Learning using privileged
information. // Neural Networks. 2009.

[4] David Lopez-Paz, Léon Bottou, Bernhard Schölkopf, Vladimir Vapnik
 Unifying distillation and privileged information

https://arxiv.org/abs/1511.03643

\bibliographystyle{unsrt}
\bibliography{jmlda-bib}
%\begin{thebibliography}{1}

%\bibitem{author09anyscience}
%    \BibAuthor{Author\;N.}
%    \BibTitle{Paper title}~//
%    \BibJournal{10-th Int'l. Conf. on Anyscience}, 2009.  Vol.\,11, No.\,1.  Pp.\,111--122.
%\bibitem{myHandbook}
%    \BibAuthor{Автор\;И.\,О.}
%    Название книги.
%    Город: Издательство, 2009. 314~с.
%\bibitem{author09first-word-of-the-title}
%    \BibAuthor{Автор\;И.\,О.}
%    \BibTitle{Название статьи}~//
%    \BibJournal{Название конференции или сборника},
%    Город:~Изд-во, 2009.  С.\,5--6.
%\bibitem{author-and-co2007}
%    \BibAuthor{Автор\;И.\,О., Соавтор\;И.\,О.}
%    \BibTitle{Название статьи}~//
%    \BibJournal{Название журнала}. 2007. Т.\,38, \No\,5. С.\,54--62.
%\bibitem{bibUsefulUrl}
%    \BibUrl{www.site.ru}~---
%    Название сайта.  2007.
%\bibitem{voron06latex}
%    \BibAuthor{Воронцов~К.\,В.}
%    \LaTeXe\ в~примерах.
%    2006.
%    \BibUrl{http://www.ccas.ru/voron/latex.html}.
%\bibitem{Lvovsky03}
%    \BibAuthor{Львовский~С.\,М.} Набор и вёрстка в пакете~\LaTeX.
%    3-е издание.
%    Москва:~МЦHМО, 2003.  448~с.
%\end{thebibliography}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}

